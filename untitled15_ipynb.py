# -*- coding: utf-8 -*-
"""「Untitled15.ipynb」的副本

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TQI7OwkhvuSr4Q9PD9nZFHGX70CYm5eA
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

import ast

from ast import literal_eval

import numpy as np

import random as rd

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/pkdd-15-predict-taxi-service-trajectory-i/

dataset=pd.read_csv("data_5.csv")
dataset

import re

lists_1st_lon = []
for i in range(0,len(dataset["POLYLINE"])):
    if dataset["POLYLINE"][i] == '[]':
        k=0
        lists_1st_lon.append(k)
    else:
        k = re.sub(r"[[|[|]|]|]]", "", dataset["POLYLINE"][i]).split(",")[0]
        lists_1st_lon.append(k)

dataset["lon_1st"] = lists_1st_lon

# First latitude
lists_1st_lat = []
for i in range(0,len(dataset["POLYLINE"])):
    if dataset["POLYLINE"][i] == '[]':
        k=0
        lists_1st_lat.append(k)
    else:
        k = re.sub(r"[[|[|]|]|]]", "", dataset["POLYLINE"][i]).split(",")[1]
        lists_1st_lat.append(k)

dataset["lat_1st"] = lists_1st_lat

dataset

dataset.drop("Unnamed: 0",axis=1,inplace=True)
dataset.drop("TAXI_ID",axis=1,inplace=True)
dataset.drop("CALL_TYPE",axis=1,inplace=True)
dataset.drop("ORIGIN_CALL",axis=1,inplace=True)
dataset.drop("ORIGIN_STAND",axis=1,inplace=True)
dataset.drop("TIMESTAMP",axis=1,inplace=True)
dataset.drop("DAY_TYPE",axis=1,inplace=True)
dataset.drop("POLYLINE",axis=1,inplace=True)
dataset

dataset.drop("Data_time",axis=1,inplace=True)
dataset

tenp_column=dataset.pop('x_to')
dataset.insert(21,"x_to",tenp_column)
dataset

tenp_column=dataset.pop('y_to')
dataset.insert(21,"y_to",tenp_column)
dataset

from datetime import datetime

def todate(time):
  a=datetime.utcfromtimestamp(time)
  year = a.year
  month = a.month
  day = a.day
  minute = a.minute
  return year,month,day,minute

years=[]
months=[]
days=[]
minutes=[]
for i in dataset['TIMESTAMP']:
  year,month,day,minute = todate(i)
  years.append(year)
  months.append(months)
  days.append(day)
  minutes.append(minute)
dataset['year']=years
dataset['month']=months
dataset['day']=days
dataset['minute']=minutes
dataset

dataset.drop("Week",axis=1,inplace=True)
dataset.drop("Weekday",axis=1,inplace=True)
dataset

X = dataset.iloc[:, :-2].values
y = dataset.iloc[:, -2:].values
X,y

y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=6)

y_train.shape

y_test.shape

import tensorflow as tf
count_layer=5
ann = tf.keras.models.Sequential()
for i in range(count_layer):
  ann.add(tf.keras.layers.Dense(units=18, activation='relu'))
ann.add(tf.keras.layers.Dense(units=2))

ann.compile(optimizer = 'adam', loss = 'MeanSquaredError', metrics = ['MeanAbsoluteError'])

ann.fit(X_train, y_train, batch_size = 100, epochs = 10)

y_pred = ann.predict(X_test)
type(y_pred)

y_pred.shape

len(y_pred)

mse = tf.keras.losses.MeanSquaredError()
mse(y_test, y_pred).numpy()

dataset_test=pd.read_csv("/content/drive/MyDrive/pkdd-15-predict-taxi-service-trajectory-i/test.csv/test.csv")
dataset_test

dataset_test.drop(['TRIP_ID'], axis=1, inplace=True)
print(f"origin {len(dataset_test['POLYLINE'])}")
count=0
locate_from=[]
locate_to=[]
for i in range(len(dataset_test['POLYLINE'])):
    f=dataset_test['POLYLINE'][i]
    f=ast.literal_eval(f)
    print(f"{i}")
    if f:
        print(f"{f[0]},{f[-1]}")
        locate_from.append(f[0])
        locate_to.append(f[-1])
    else:
        count=count+1
        print(f"{i} is empty")
        dataset_test.drop([i],axis=0,inplace=True)
dataset_test['from']=locate_from
dataset_test['to']=locate_to
dataset_test

vectors = []
for i in range(len(dataset_test['POLYLINE'])):

    f = dataset_test['POLYLINE'][i]

    f = ast.literal_eval(f)

    print(f"{i}")

    vector = []

    for j in range(1, len(f)):

        x = np.array(f[j])-np.array(f[j-1])

        vector.append(x)

    vectors.append(vector)

dataset_test["vectors"] = vectors
dataset_test

dataset_test.drop("CALL_TYPE",axis=1,inplace=True)
dataset_test.drop("ORIGIN_CALL",axis=1,inplace=True)
dataset_test.drop("ORIGIN_STAND",axis=1,inplace=True)
#dataset_test.drop("TIMESTAMP",axis=1,inplace=True)
dataset_test.drop("DAY_TYPE",axis=1,inplace=True)
dataset_test.drop("POLYLINE",axis=1,inplace=True)
dataset_test

dataset_test.drop("TAXI_ID",axis=1,inplace=True)
dataset_test

import datetime

# DECODING TIME SIGNATURE TEST DATA
dataset_test["TIMESTAMP"] = [float(time) for time in dataset_test["TIMESTAMP"]]
dataset_test["data_time"] = [datetime.datetime.fromtimestamp(time, datetime.timezone.utc) for time in dataset_test["TIMESTAMP"]]
dataset_test

for i in range(0,len(dataset_test["vectors"])):
  if len(dataset_test["vectors"][i])<5:
    print(f'第{i}列不足5,僅有{len(dataset_test["vectors"][i])}個元素')
    for x in range(0,5-len(dataset_test["vectors"][i])):
      dataset_test["vectors"][i].insert(-1,[0,0])
dataset_test

dataset_test.drop("TIMESTAMP",axis=1,inplace=True)
dataset_test

dataset_test["year"] = dataset_test["data_time"].dt.year
dataset_test["month"] = dataset_test["data_time"].dt.month
dataset_test["week"] = dataset_test["data_time"].dt.week
dataset_test["day"] = dataset_test["data_time"].dt.day
dataset_test["hour"] = dataset_test["data_time"].dt.hour
dataset_test["min"] = dataset_test["data_time"].dt.minute
dataset_test["weekday"] =dataset_test["data_time"].dt.weekday
dataset_test

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
dataset_test["MISSING_DATA"]= le.fit_transform(dataset_test["MISSING_DATA"])
x_from=[]
y_from=[]
for i in range(len(dataset_test['from'])):
  x=dataset_test['from'][i][0]
  y=dataset_test['from'][i][1]
  x_from.append(x)
  y_from.append(y)
dataset_test["x_from"]=x_from
dataset_test["y_from"]=y_from
x_to=[]
y_to=[]
for i in range(len(dataset_test['to'])):
  x=dataset_test['to'][i][0]
  y=dataset_test['to'][i][1]
  x_to.append(x)
  y_to.append(y)
dataset_test["x_to"]=x_to
dataset_test["y_to"]=y_to
dataset_test

from tqdm import tqdm
x_1=[]
x_2=[]
x_3=[]
x_4=[]
x_5=[]
y_1=[]
y_2=[]
y_3=[]
y_4=[]
y_5=[]
pick=5
for i in tqdm(range(len(dataset_test['vectors']))):
  j=dataset_test['vectors'][i]
  if len(j)<pick:
    dataset_test.drop([i],axis=0,inplace=True)
    continue
  L1=rd.sample(range(0,(len(dataset_test['vectors'][i]))),pick)
  L1=sorted(L1)
  x1=j[L1[0]][0]
  y1=j[L1[0]][1]
  x2=j[L1[1]][0]
  y2=j[L1[1]][1]
  x3=j[L1[2]][0]
  y3=j[L1[2]][1]
  x4=j[L1[3]][0]
  y4=j[L1[3]][1]
  x5=j[L1[4]][0]
  y5=j[L1[4]][1]
  x_1.append(x1)
  y_1.append(y1)
  x_2.append(x2)
  y_2.append(y2)
  x_3.append(x3)
  y_3.append(y3)
  x_4.append(x4)
  y_4.append(y4)
  x_5.append(x5)
  y_5.append(y5)
dataset_test["x_1"]=x_1
dataset_test["y_1"]=y_1
dataset_test["x_2"]=x_2
dataset_test["y_2"]=y_2
dataset_test["x_3"]=x_3
dataset_test["y_3"]=y_3
dataset_test["x_4"]=x_4
dataset_test["y_4"]=y_4
dataset_test["x_5"]=x_5
dataset_test["y_5"]=y_5
dataset_test.drop("from",axis=1,inplace=True)
dataset_test.drop("to",axis=1,inplace=True)
dataset_test.drop("vectors",axis=1,inplace=True)
dataset_test

dataset_test.drop("data_time",axis=1,inplace=True)
dataset_test

dataset_test

tenp_column=dataset_test.pop('x_to')
dataset_test.insert(21,"x_to",tenp_column)
dataset_test

tenp_column=dataset_test.pop('y_to')
dataset_test.insert(21,"y_to",tenp_column)
dataset_test

dataset_test.drop("week",axis=1,inplace=True)
dataset_test.drop("weekday",axis=1,inplace=True)
dataset_test

test_X = dataset_test.iloc[:, :-2].values
test_y = dataset_test.iloc[:, -2:].values
test_X,test_y

test_y_pred = ann.predict(test_X)

mse = tf.keras.losses.MeanSquaredError()
mse(test_y, test_y_pred).numpy()

test_y_pred

np.savetxt("test_y_pred",test_y_pred , delimiter=',')

dataset_sb=pd.read_csv("/content/drive/MyDrive/pkdd-15-predict-taxi-service-trajectory-i/submission.csv")
dataset_sb

y_sb=dataset_sb.iloc[:,1:].values
y_sb

y_sb.shape

mse = tf.keras.losses.MeanSquaredError()
mse(y_sb,test_y_pred).numpy()